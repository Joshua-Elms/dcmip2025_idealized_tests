import numpy as np
import pandas as pd
import xarray as xr
from pathlib import Path
import scipy
import subprocess
import logging


def run_fortran_executable(
    executable_path,
    nlat,
    nlev,
    zn,
    zb,
    zrh0,
    zt0,
    zu0,
    zgamma,
    moisture,
    filename: Path,
):
    """
    WARNING!!!
    THIS FUNCTION CAN CAUSE THE SHELL TO HANG.
    PREPARE TO MANUALLY CLOSE IT AFTER RUNNING.

    Runs a Fortran executable with the specified arguments.

    Parameters:
        executable_path (str): Path to the Fortran executable.
        nlat (int): Number of latitude ticks.
        nlev (int): Number of levels.
        zn (float): Jet width.
        zb (float): Jet height.
        zrh0 (float): Surface level relative humidity (%).
        zt0 (float): Average surface virtual temperature (K).
        zu0 (float): Affects amplitude of zonal mean wind speed (m/s).
        zgamma (float): Lapse rate (K/m).
        moisture (int): 41 for dry run, 42 for moist.
        filename (Path): Output CSV file path.

    Returns:
        stdout (str): Standard output from the executable.
        stderr (str): Standard error from the executable.
    """
    args = [
        str(nlat),
        str(nlev),
        str(zn),
        str(zb),
        str(zrh0),
        str(zt0),
        str(zu0),
        str(zgamma),
        str(moisture),
        filename,
    ]
    # fortran refuses to write over extant file ... fine.
    if filename.exists():
        return None, "CSV already exists, skipping execution."

    try:
        result = subprocess.run(
            [executable_path] + args, text=True, capture_output=True, check=True
        )
        return result.stdout, result.stderr
    except subprocess.CalledProcessError as e:
        print(f"Error running executable: {e}")
        print(f"Standard Error: {e.stderr}")
        return None, e.stderr


def read_to_df(fort_path: Path, nlat: int) -> tuple[pd.DataFrame, int]:

    # load the data
    mylist = []

    for i, chunk in enumerate(
        pd.read_csv(fort_path, header=0, index_col=None, chunksize=2000)
    ):
        mylist.append(chunk)

    f_in = pd.concat(mylist, axis=0)
    del mylist

    # make sure given nlat is consistent with the input data
    assert (
        f_in.shape[0] % nlat == 0
    ), f"invalid dimensions: nlat x nlat != {f_in.shape[0]} (len(f_in))"
    nlev = f_in.shape[0] // nlat

    # remove leading/trailing whitespace from column names
    f_in.columns = [c.strip() for c in f_in.columns]

    return f_in, nlev


def read_metadata(
    metadata_dir: Path,
    lat_fname: str,
    lon_fname: str,
    all_lev_fname: str,
    model_lev_fname: str,
) -> tuple[np.ndarray, np.ndarray, np.ndarray]:
    # load latitude and vertical level data
    lat = np.load(metadata_dir / lat_fname)
    lon = np.load(metadata_dir / lon_fname)
    all_lev = pd.read_csv(metadata_dir / all_lev_fname, header=0, index_col=None).values
    keep_plevs = pd.read_csv(
        metadata_dir / model_lev_fname, header=None
    ).values.flatten()

    return lat, lon, all_lev.T, keep_plevs


def compute_tcwv(q: np.ndarray, lev: np.ndarray) -> np.ndarray:
    # compute total column water vapor, see https://resources.eumetrain.org/data/3/359/print_2.htm for similar formula
    g = 9.80665  # m/s^2

    pa = 100 * lev  # convert hPa to Pa

    tcwv = -(1 / g) * scipy.integrate.trapezoid(q, pa, axis=1)

    return tcwv


def generate_superset_of_initial_conditions(
    csv_path: Path,
    metadata_dir: Path,
    latitudes_fname: str,
    longitudes_fname: str,
    all_plevels_fname: str,
    model_plevels_fname: str,
    nc_path: Path | None = None,
):
    """
    Processes a CSV file generated by the Fortran executable into an xarray dataset.

    Parameters:
        csv_path (Path): Path to the input CSV file.
        metadata_dir (Path): Directory containing metadata files.
        latitudes_fname (str): Filename for latitude data.
        longitudes_fname (str): Filename for longitude data.
        all_plevels_fname (str): Filename for all pressure levels data.
        model_plevels_fname (str): Filename for model pressure levels data.
        nc_path (Path | None): Path to save the output NetCDF file, or None to merely return the dataset. Default is None.

    Returns:
        xr.Dataset: Processed xarray dataset.
    """

    # read latitude and vertical levels data
    lat, lon, (plev, etalev), keep_plev = read_metadata(
        metadata_dir,
        latitudes_fname,
        longitudes_fname,
        all_plevels_fname,
        model_plevels_fname,
    )
    plev, etalev = plev.T, etalev.T
    nlat = len(lat)

    df, nlev = read_to_df(csv_path, nlat)

    # this is important; the fortran code only outputs
    # the first latitude column of ZRH, so we need to tile it
    # to get the full 2D array
    df["ZRH"] = np.tile((df["ZRH"].values[:nlev]), nlat)
    # convert to percentage
    df["ZRH"] *= 100
    sfc_rh = df["ZRH"].values[0]

    # compute total column water vapor
    q = df["ZQ"].values.reshape(nlat, nlev)
    tcwv = compute_tcwv(q, plev)

    # keep only the desired vertical levels
    keep_idxs = np.where(np.isin(plev, keep_plev))[0]

    # create pressure vars, both constant due to initiation at sea level
    msl = np.full_like(tcwv, 1013.25) * 100  # convert hPa to Pa

    # create xarray dataset
    ds_out = xr.Dataset(
        {
            "tcwv": (["lat"], tcwv.copy()),  # water vapour
            "sp": (["lat"], msl.copy()),  # surface pressure
            "msl": (["lat"], msl.copy()),  # mean sea level pressure
            "tp06": (
                ["lat"],
                np.full_like(tcwv, 0.0),
            ),  # total precipitation in last 6 hours
            "z": (["lat"], np.full_like(tcwv, 0.0)),  # geopotential height at surface
            "lsm": (["lat"], np.full_like(tcwv, 0.0)),  # land-sea mask, all ocean
        },
        coords={
            "lat": lat,
        },
    )

    # iteratively add pressure-coordinate necessary variables and levels to the dataset
    for lname, uname in [
        ("u", "ZU"),
        ("v", "ZV"),
        ("t", "ZT"),
        ("z", "ZPHI_F"),
        ("q", "ZQ"),
        ("r", "ZRH"),
    ]:

        # reshape to (nlat, nlev) and keep only the vertical levels needed for models
        sub = df[uname].values.reshape(nlat, nlev)[:, keep_idxs]

        for i, lev in enumerate(keep_plev):
            ds_out[f"{lname}{lev}"] = xr.DataArray(sub[:, i], dims=("lat",))
            print(f"Mean of {lname}{lev}: {ds_out[f'{lname}{lev}'].mean().item()}")

    # add height level variables to dataset, all at lowest model level [0] or 1013.25 hPa
    u = df["ZU"].values.reshape(nlat, nlev)
    v = df["ZV"].values.reshape(nlat, nlev)
    t = df["ZT"].values.reshape(nlat, nlev)
    # lowest model level instead of 10 meter winds
    ds_out["u10m"] = (["lat"], u[:, 0])
    ds_out["v10m"] = (["lat"], v[:, 0])
    # lowest model level instead of 100 meter winds
    ds_out["u100m"] = (["lat"], u[:, 0])
    ds_out["v100m"] = (["lat"], v[:, 0])
    # lowest model level instead of 2 meter temperature
    ds_out["t2m"] = (["lat"], t[:, 0])

    # since the bouvier atmosphere is hydrostatically balanced, w = 0
    w = np.zeros_like(df["ZQ"].values.reshape(nlat, nlev)[:, keep_idxs])
    ds_out["w"] = xr.DataArray(w, dims=("lat", "level"))

    # add dewpoint temperature
    t2mC = df["ZT"].values.reshape(nlat, nlev)[:, 0] - 273.15
    # formula from https://en.wikipedia.org/wiki/Dew_point
    b = 17.625
    c = 243.04
    gamma = np.log(sfc_rh / 100) + (b * t2mC) / (c + t2mC)
    dewpt = (c * gamma) / (b - gamma) + 273.15
    ds_out["d2m"] = (["lat"], dewpt)

    # expand all variables along longitude dimension
    # while Bouvier et al. only outputs one meridional slice, we need the whole domain for SFNO
    ds_out = ds_out.expand_dims({"lon": lon}, axis=1)

    # add time dimension because it's required for the inference function
    ds_out = ds_out.expand_dims(
        {
            "time": np.array(
                [np.datetime64("2000-01-01T00:00:00").astype("datetime64[ns]")]
            )
        },
        axis=0,
    )

    # save to disk
    if nc_path is not None:
        ds_out.to_netcdf(nc_path)

    return ds_out


if __name__ == "__main__":

    ds = generate_superset_of_initial_conditions(
        csv_path=Path(
            "/N/slate/jmelms/projects/dcmip2025_idealized_tests/initial_conditions/Bouvier/fields.csv"
        ),
        nc_path=Path(
            "/N/slate/jmelms/projects/dcmip2025_idealized_tests/initial_conditions/Bouvier/super_IC.nc"
        ),
        metadata_dir=Path(
            "/N/slate/jmelms/projects/dcmip2025_idealized_tests/initial_conditions/Bouvier/metadata"
        ),
        latitudes_fname="latitude.npy",
        longitudes_fname="longitude.npy",
        all_plevels_fname="levels_full.txt",
        model_plevels_fname="levels_model.txt",
    )
